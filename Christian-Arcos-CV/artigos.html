<!doctype html>
<html lang="es">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="normalize_css/normalize.css">
    
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.1.0/css/flag-icon.min.css" rel="stylesheet">
    <link rel="stylesheet"  type="text/css" href="css/style.css">
    <style> .jumbotron{background-image: url(images/baner.jpg); 
      text-align: center;
      padding-top: 10rem;
      padding-bottom: 10rem;
      text-shadow: 2px 2px rgba(163, 161, 161, 0.719);}
      
      .lead {
      color: rgba(255, 255, 212, 0.192);
      font-weight: bold;
      }      
      </style>

  <title>Pesquisa</title>

  </head>
  <body data-spy="scroll" data-target="#navbarScroll" data-offset="100">

    <!--baner o jumbotron-->

    <div class="jumbotron jumbotron-fluid bg-cover" id="jumbo" >
        <div class="container jumboHeaderImg">
          <h2 class="display-3"> <strong> CHRISTIAN ARCOS </strong> </h2>
          <p class="lead"><em> As vezes são as pessoas que ninguém espera nada, que fazem as coisas que ninguém consegue imaginar. <br> "Alan Turing".</em></p>
        </div>
      </div>

   <!--Cuerpo del cv-->

   <div class="container">
    <div class="center-block head">
        <h1 class="display-5"> <strong> Declaração de Pesquisa: Ph.D. Christian Dayan Arcos Gordillo <br>
                                       Pesquisa em inteligência artificial e processamento de sinais </strong> </h1>
    </div>

    <div class="row" >
            
        <div class="container">
          <p class="text-justify parrafo"> 
            
          Um breve resumo da minha produção científica refere-se a publicações em periódicos e conferências. <br>
         </p>
         <ul>
         <li> <p class="text-justify parrafo">
           <a href="https://ieeexplore.ieee.org/document/8852363"> <strong> <ins> Ideal Neighbourhood Mask for Speech Enhancement Using Deep Neural Networks </ins></strong></a> <br>
           <small class="text-muted">The 2019 International Joint Conference on Neural  Networks (IJCNN)” The Special Session on Deep Neural Audio Processing, in Budapest, Hungary</small> </p>
            <p class="text-justify"><strong>Abstract: </strong> Degradation of speech signal due to adverse conditions is the major challenge for automatic speech recognition (ASR) systems.
               This paper introduces a novel approach to estimate an Ideal Neighbourhood Mask (INM) for speech segregation based on deep neural networks estimator. The method described here is 
               based on the local binary patterns (LBP) technique often used in digital image processing. Ideal Neighbourhood Mask will indicate which time-frequency (T-F) units of the noisy 
               speech are canceled. The performance assessment of the proposed application in conjunction with the traditional mask techniques, i.e., Ideal Binary Mask (IBM) and Ideal Ratio Mask (IRM), 
               are carried out under various environments regarding the objective speech quality measures. The recognition experiments including 
              results in the AURORA IV framework indicate that the proposed scheme, when applied in adverse environments yield significantly better performance than the conventional techniques. </p>
          </li>

          <li> <p class="text-justify parrafo">
            <a href="https://www.researchgate.net/publication/335998482_Segregacao_de_Voz_Usando_Mascaramento_INM_sobre_o_Banco_de_Filtros_Gammatone"> <strong> <ins> Segregação de Voz Usando Mascaramento INM sobre o Banco de Filtros Gammatone </ins></strong></a> <br>
            <small class="text-muted">XXXVI Simpósio Brasileiro de Telecomunicações e processamento de sinais (SBrT-2018), Campina Grande, PB</small> </p>
             <p class="text-justify"><strong>Abstract: </strong> This paper presents an innovative approach thatemploys an ideal neighbourhood mask (INM) that has the abilityto efficiently use Local Binary Pattern (LBP) 
              to indicate whichTime-Frequency units of the corrupted voice are dominated bynoise. Experimental results obtained with a DNN based voicerecogniser in noisy environments demonstrate that the 
              proposedtechnique achieves significant improvements in terms of worderror rate corroborating the superiority of the proposed schemein comparison with the traditional masking algorithms IBM 
              and IRM. </p>
           </li>

           <li> <p class="text-justify parrafo">
            <a href="https://ieeexplore.ieee.org/document/8304528"> <strong> <ins> Ideal neighbourhood mask for speech enhancement </ins></strong></a> <br>
            <small class="text-muted">Electronics Letters, January 2018, the Institute of Engineering and Technology (the IET)</small> </p>
             <p class="text-justify"><strong>Abstract: </strong> A novel approach for speech enhancement applications by applying spectral mask estimation is introduced. The new application uses the local binary
               patterns to estimate an ideal neighbourhood mask. This will indicate which time-frequency units of the noisy speech are dominated by the noise. The performance assessment of the
                proposed application in conjunction with the traditional mask techniques, i.e. ideal binary mask and ideal ratio mask, are carried out under various environments in terms of the 
                objective speech quality measures, as well as word error rate performance in speech recognition systems using deep neural networks. Results indicated that the proposed mask yielded 
                significantly better performance than the conventional techniques. </p>
           </li>

           <li> <p class="text-justify parrafo">
            <a href="https://publications.waset.org/10008257/speech-enhancement-using-wavelet-coefficients-masking-with-local-binary-patterns"> <strong> <ins> Speech Enhancement Using Wavelet Coefficients Masking with Local Binary Patterns </ins></strong></a> <br>
            <small class="text-muted">International Journal of Computer, Electrical, Automation, Control and Information Engineering, 11(12), 1216 - 1221</small> </p>
             <p class="text-justify"><strong>Abstract: </strong> In this paper, we present a wavelet coefficients masking based on Local Binary Patterns (WLBP) approach to enhance the temporal spectra of the wavelet 
              coefficients for speech enhancement. This technique exploits the wavelet denoising scheme, which splits the degraded speech into pyramidal subband components and extracts frequency 
              information without losing temporal information. Speech enhancement in each high-frequency subband is performed by binary labels through the local binary pattern masking that encodes 
              the ratio between the original value of each coefficient and the values of the neighbour coefficients. This approach enhances the high-frequency spectra of the wavelet transform instead 
              of eliminating them through a threshold. A comparative analysis is carried out with conventional speech enhancement algorithms, demonstrating that the proposed technique achieves 
              significant improvements in terms of PESQ, an international recommendation of objective measure for estimating subjective speech quality. Informal listening tests also show that the 
              proposed method in an acoustic context improves the quality of speech, avoiding the annoying musical noise present in other speech enhancement techniques. Experimental results obtained 
              with a DNN based speech recognizer in noisy environments corroborate the superiority of the proposed scheme in the robust speech recognition scenario. </p>
           </li>


           <li> <p class="text-justify parrafo">
            <a href="https://ieeexplore.ieee.org/document/7760438"> <strong> <ins> Median filtering the  temporal probability distribution in histogram mapping for robust  continuous speech recognition </ins></strong></a> <br>
            <small class="text-muted">IEEE 24th European Signal Processing Conference  (EUSIPCO), 2016  (pp. 1198-1201). </small> </p>
             <p class="text-justify"><strong>Abstract: </strong> The nonlinear distortion in the cepstral coefficients domain introduced by additive noise in the speech signal, results in high degradation performance in systems 
              of Automatic Speech Recognition (ASR). For this reason, we propose a median filter which smooths the probability distribution functions of degraded features, thus reducing the mismatch 
              between training data and test. The new proposal uses a histogram mapping to obtain the PDFs (probability distribution functions) of each feature vector and applies a nonlinear median 
              filtering before mapping to the reference PDF. The algorithm efficiency is analyzed and compared to a recently proposed linear mean filtering technique on the PDFs. From the experimental 
              results it can be concluded that the histogram smoothing through the median nonlinear filtering reduces the mismatch between training data and test, improving the system performance under 
              adverse conditions. </p>
           </li>


           <li> <p class="text-justify parrafo">
            <a href="http://www.sbrt.org.br/sbrt2016/anais/SEPosters/02-avaliacaodeumnovoreconhecedor.pdf"> <strong> <ins> Avaliação de um Novo Reconhecedor de Voz Robusto Baseado em Filtragem por
              Mediana da Função Distribuição de Probabilidade Usando o Corpus AURORA-4 </ins></strong></a> <br>
            <small class="text-muted">XXXIV Simpósio Brasileiro de Telecomunicações SBrT 2016, Santarém, PA. </small> </p>
             <p class="text-justify"><strong>Abstract: </strong> This article examines and presents contributions to the robustness of cepstral attributes PNCC used in automatic speech recognition (ASR), through a non-linear filtering on the
              probability distribution functions (PDFs) of the attributes corrupted. Previous work has demostrated that Histogram mapping (HMAP) reduced the word error rate of the recognition system.
              However the HMAP introduces a small mismatch when there is no distortion of the test data, generating a loss of information of each noise-free features. In this letter we propose a novel
              approach to this problem, known as MED-MAP, wich consist in smoothing the PDFs for each attribute vector using median filtering. Experimental results on the AURORA-4 database have
              been and the effectiveness of the algorithm is analyzed in comparation with a linear filter technique on the PDFs. concluding that the smoothing of probability distributions through non-linear
              filtering improves system performance in adverse conditions </p>
           </li>


           <li> <p class="text-justify parrafo">
            <a href="https://ieeexplore.ieee.org/document/6948038"> <strong> <ins> PNCC Features and  FNN - MAP Compensation Techniques for Continuous Speech Recognition</ins></strong></a> <br>
            <small class="text-muted">International Telecommunications Symposium (ITS 2014), São Paulo. </small> </p>
             <p class="text-justify"><strong>Abstract: </strong> One of the biggest problems of a speech recognition system is the signal degradation due to adverse conditions. Such situations usually lead to mismatch between the 
              test conditions and the training data, caused by non-linear distortion. The authors propose a histogram mapping followed by a filter through neural networks techniques (based on the 
              features compensation), in order to minimize the misfit caused by noise insertion in the speech signal. The proposed method has been evaluated using the TIMIT and Noisex-92 databases.
               Recognition results show that the histogram mapping combined with filter with neural networks in the field of the cepstral coefficients do improve the recognition rates. </p>
           </li>


           <li> <p class="text-justify parrafo">
            <a href="https://ieeexplore.ieee.org/document/6889195"> <strong> <ins> Speech Enhancement and Features Compensation Algorithms for Continuous Speech Recognition</ins></strong></a> <br>
            <small class="text-muted">2nd IEEE China Summit and International Conference on Signal and Information Processing 2014, Xian. </small> </p>
             <p class="text-justify"><strong>Abstract: </strong> The degradation of the speech signal due to adverse conditions generates low accuracy rates in speech recognition systems. The authors propose mixing two methods: 
              pre-extraction of features for speech enhancement and post-extraction of features for features compensation. According to their main focus, they are fundamentally oriented to minimize the 
              misfit caused by noise insertion in the speech signal. These methods will be applied before and after the extraction of features, respectively, therefore allowing the best possible 
              estimation of the clear signal from its degraded version.</p>
           </li>


           <li> <p class="text-justify parrafo">
            <a href="http://gestao.sbrt.org.br/simposios/artigo/visualizar/a/11"> <strong> <ins> Reconhecimento de Voz Contínua com Atributos PNCC e Métodos de Robustez WD e MAP</ins></strong></a> <br>
            <small class="text-muted">XXXI Simpósio Brasileiro de Telecomunicações, 2013, Fortaleza. </small> </p>
             <p class="text-justify"><strong>Resumo: </strong> A degradação do sinal de voz devido a condições ad-versas gera baixas taxas de acerto nos sistemas de reconhecimento de voz. Os autores propõem a mistura de dois métodos: 
              pré-extração de atributos para realce de fala e pós-extração de atributos para compensação de características. Segundo seu foco principal, esses métodos estão orientados fundamentalmente a
               minimizar os desajustes causados pela inserção de ruído no sinal de voz. Estes métodos serão aplicados antes e depois da extração de atributos, respectivamente, conseguindo assim estimar o
                máximo possível o sinal limpo a partir da sua versão degradada.
              .</p>
           </li>

         

        </ul>
        </div>
  </div>

   </div>

  <!--FOOTER-->

  <div class="footer">
      <div class="container">

        <div class="pie text-center">
        <span class="copy text-muted">www.christianarcos.co - © 2020 Copiryght </span>
      </div>
              <!--redes sociales-->
             
              <div class="footer_area_item text-center">
                <a href="https://github.com/TottiPuc"><img src="images/github.png" alt="github"> </a>
                <a href="https://www.linkedin.com/in/christian-dayan-arcos-gordillo/"><img src="images/linked.PNG" alt="linkeid"> </a>
                <a href="https://www.youtube.com/channel/UCRlazgx5-5_-1xtP8llRg-A"><img src="images/youtube.png" alt="youtube"> </a>
                <a href="#"><img src="images/blog.PNG" alt="proximamente"> </a>

        </div> 
                
            
      </div>
       
  </div>



    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  </body>
</html>